# ============================================================================
# DECENTRALIZED AI ARCHITECTURE - EDGE RAG CONFIGURATION
# ============================================================================
# Masterthesis: "Enhancing Reasoning Fidelity in Quantized SLMs on Edge"
# 
# VERSION 2.1.0 - CORRECTED METRIC CONFIGURATION
# 
# CRITICAL CHANGES (v2.1.0):
# - Added distance_metric: "cosine" to vector_store section
# - This fixes the similarity score computation bug
# - Previous versions defaulted to L2 distance, causing incorrect scores
#
# Expected Impact:
# - Similarity scores should increase from 0.17-0.25 to 0.70-0.90
# - Retrieval coverage should improve from 0% to 80%+

project:
  name: "Graph-Augmented Edge-RAG"
  version: "2.1.0"
  author: "Jan Nietzard"
  institution: "RWTH Aachen"

# ============================================================================
# LANGUAGE MODEL CONFIGURATION
# ============================================================================
llm:
  provider: "ollama"
  model_name: "phi3"
  base_url: "http://localhost:11434"
  temperature: 0.3
  top_p: 0.9
  top_k: 40
  max_tokens: 256

# ============================================================================
# EMBEDDING MODEL
# ============================================================================
embeddings:
  provider: "ollama"
  model_name: "nomic-embed-text"
  base_url: "http://localhost:11434"
  embedding_dim: 768  # Auto-detected, but can be specified for validation

# ============================================================================
# DOCUMENT INGESTION & CHUNKING
# ============================================================================
chunking:
  mode: "standard"
  chunk_size: 512
  chunk_overlap: 128
  min_chunk_size: 200
  enable_pdf_cleaning: true
  
  separators:
    - "\n\n"
    - "\n"
    - ". "
    - " "
    - ""

# ============================================================================
# VECTOR STORE (LanceDB)
# ============================================================================
vector_store:
  provider: "lancedb"
  db_path: "./data/vector_db"
  index_type: "ivfflat"
  
  # =========================================================================
  # CRITICAL: Distance metric specification
  # =========================================================================
  # LanceDB supports: "cosine", "l2" (euclidean), "dot"
  # For text embeddings, "cosine" is the standard choice.
  #
  # WARNING: If you change this after indexing, you must re-index all documents!
  # =========================================================================
  distance_metric: "cosine"
  
  # L2 normalization for embeddings
  # When true, vectors are normalized to unit length before storage.
  # This makes cosine similarity equivalent to dot product (faster computation).
  normalize_embeddings: true
  
  # Retrieval parameters
  top_k_vectors: 10
  similarity_threshold: 0.3  # Minimum similarity score [0.0, 1.0]

# ============================================================================
# KNOWLEDGE GRAPH (NetworkX)
# ============================================================================
graph:
  enabled: true
  provider: "networkx"
  graph_path: "./data/knowledge_graph"
  entity_extraction_enabled: true
  entity_extraction_method: "keyword"
  
  relation_types:
    - "mentions"
    - "references"
    - "defines"
    - "extends"
    - "part_of"
    - "follows"
  
  max_hops: 2
  top_k_entities: 5

# ============================================================================
# RETRIEVAL AUGMENTED GENERATION (RAG)
# ============================================================================
rag:
  retrieval_mode: "hybrid"
  
  # Current evaluation: Vector-only (graph_weight=0)
  # This isolates vector retrieval performance for initial testing.
  # Adjust weights for hybrid evaluation after vector baseline is established.
  vector_weight: 1.0
  graph_weight: 0.0
  
  reranking_enabled: false
  query_expansion_enabled: false

# ============================================================================
# QUANTIZATION SETTINGS
# ============================================================================
quantization:
  enabled: true
  bits: 4
  group_size: 128

# ============================================================================
# DATA PATHS
# ============================================================================
paths:
  root: "./"
  data: "./data"
  documents: "./data/documents"
  vector_db: "./data/vector_db"
  graph_db: "./data/knowledge_graph"
  logs: "./logs"
  cache: "./cache"

# ============================================================================
# LOGGING
# ============================================================================
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "./logs/edge_rag.log"

# ============================================================================
# PERFORMANCE TUNING
# ============================================================================
performance:
  batch_size: 32
  num_workers: 2
  device: "cpu"
  cache_embeddings: true
  max_cache_size_mb: 512